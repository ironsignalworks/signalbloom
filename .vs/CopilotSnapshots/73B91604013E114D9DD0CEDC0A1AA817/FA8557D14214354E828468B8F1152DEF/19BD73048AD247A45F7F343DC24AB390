export class MicAnalyser {
  ctx?: AudioContext;
  analyser?: AnalyserNode;
  data?: Uint8Array<ArrayBuffer>;
  gain = 1;
  source?: MediaStreamAudioSourceNode | MediaElementAudioSourceNode;

  async init() {
    if (this.ctx) return;
    this.ctx = new (window.AudioContext || (window as any).webkitAudioContext)();
    const stream = await navigator.mediaDevices.getUserMedia({ 
      audio: { 
        echoCancellation: false,
        noiseSuppression: false,
        autoGainControl: false 
      }, 
      video: false 
    });
    this.source = this.ctx.createMediaStreamSource(stream);
    this.setupAnalyser();
  }

  async initFromFile(file: File) {
    if (!this.ctx) {
      this.ctx = new (window.AudioContext || (window as any).webkitAudioContext)();
    }
    
    // Stop existing source if any
    if (this.source) {
      this.source.disconnect();
    }

    const arrayBuffer = await file.arrayBuffer();
    const audioBuffer = await this.ctx.decodeAudioData(arrayBuffer);
    
    const source = this.ctx.createBufferSource();
    source.buffer = audioBuffer;
    source.loop = true;
    
    this.source = source;
    this.setupAnalyser();
    source.start(0);
  }

  private setupAnalyser() {
    if (!this.ctx || !this.source) return;
    
    this.analyser = this.ctx.createAnalyser();
    this.analyser.fftSize = 2048;
    this.analyser.smoothingTimeConstant = 0.75;
    this.analyser.minDecibels = -90;
    this.analyser.maxDecibels = -10;
    
    this.source.connect(this.analyser);
    this.data = new Uint8Array(this.analyser.frequencyBinCount) as Uint8Array<ArrayBuffer>;
  }

  /** returns a smoothed 0..1 level */
  level(): number {
    if (!this.analyser || !this.data) return 0;
    this.analyser.getByteFrequencyData(this.data);
    let acc = 0;
    for (let i = 0; i < this.data.length; i++) acc += this.data[i];
    const avg = acc / this.data.length;            // 0..255
    return Math.min(1, (avg / 128) * this.gain);   // adjusted sensitivity
  }
}
